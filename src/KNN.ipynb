{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 3374\n",
      "Test Data: 802\n",
      "Value of k: 5\n",
      "\n",
      "Final Accuracy: 19.45137157107232%\n",
      "\n",
      "Class Label: 3\n",
      "\tPrecision: 50.0%\n",
      "\tRecall: 20.0%\n",
      "\tF1-Score: 28.571428571428573%\n",
      "\n",
      "Class Label: 4\n",
      "\tPrecision: 44.44444444444444%\n",
      "\tRecall: 33.33333333333333%\n",
      "\tF1-Score: 38.095238095238095%\n",
      "\n",
      "Class Label: 5\n",
      "\tPrecision: 26.31578947368421%\n",
      "\tRecall: 19.230769230769234%\n",
      "\tF1-Score: 22.22222222222222%\n",
      "\n",
      "Class Label: 6\n",
      "\tPrecision: 39.39393939393939%\n",
      "\tRecall: 20.0%\n",
      "\tF1-Score: 26.530612244897956%\n",
      "\n",
      "Class Label: 7\n",
      "\tPrecision: 23.25581395348837%\n",
      "\tRecall: 29.411764705882355%\n",
      "\tF1-Score: 25.974025974025974%\n",
      "\n",
      "Class Label: 8\n",
      "\tPrecision: 20.87912087912088%\n",
      "\tRecall: 18.446601941747574%\n",
      "\tF1-Score: 19.587628865979383%\n",
      "\n",
      "Class Label: 9\n",
      "\tPrecision: 21.73913043478261%\n",
      "\tRecall: 24.59016393442623%\n",
      "\tF1-Score: 23.076923076923077%\n",
      "\n",
      "Class Label: 10\n",
      "\tPrecision: 19.736842105263158%\n",
      "\tRecall: 26.31578947368421%\n",
      "\tF1-Score: 22.556390977443606%\n",
      "\n",
      "Class Label: 11\n",
      "\tPrecision: 16.3265306122449%\n",
      "\tRecall: 17.97752808988764%\n",
      "\tF1-Score: 17.112299465240643%\n",
      "\n",
      "Class Label: 12\n",
      "\tPrecision: 18.421052631578945%\n",
      "\tRecall: 10.9375%\n",
      "\tF1-Score: 13.72549019607843%\n",
      "\n",
      "Class Label: 13\n",
      "\tPrecision: 8.108108108108109%\n",
      "\tRecall: 6.976744186046512%\n",
      "\tF1-Score: 7.5%\n",
      "\n",
      "Class Label: 14\n",
      "\tPrecision: 16.666666666666664%\n",
      "\tRecall: 13.636363636363635%\n",
      "\tF1-Score: 15.0%\n",
      "\n",
      "Class Label: 15\n",
      "\tPrecision: 13.636363636363635%\n",
      "\tRecall: 15.789473684210526%\n",
      "\tF1-Score: 14.634146341463415%\n",
      "\n",
      "Class Label: 16\n",
      "\tPrecision: 12.5%\n",
      "\tRecall: 7.6923076923076925%\n",
      "\tF1-Score: 9.523809523809524%\n",
      "\n",
      "Class Label: 17\n",
      "\tPrecision: 0.0%\n",
      "\tRecall: 0.0%\n",
      "\tF1-Score: 0%\n",
      "\n",
      "Class Label: 18\n",
      "\tPrecision: 0.0%\n",
      "\tRecall: 0.0%\n",
      "\tF1-Score: 0%\n",
      "\n",
      "Class Label: 19\n",
      "\tPrecision: 0.0%\n",
      "\tRecall: 0.0%\n",
      "\tF1-Score: 0%\n",
      "\n",
      "Class Label: 20\n",
      "\tPrecision: 11.11111111111111%\n",
      "\tRecall: 20.0%\n",
      "\tF1-Score: 14.285714285714286%\n",
      "\n",
      "Class Label: 21\n",
      "\tPrecision: 0.0%\n",
      "\tRecall: 0.0%\n",
      "\tF1-Score: 0%\n",
      "\n",
      "Class Label: 22\n",
      "\tPrecision: 0.0%\n",
      "\tRecall: 0.0%\n",
      "\tF1-Score: 0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# function to read dataset from file\n",
    "def readDataset(filename):\n",
    "    dataset = pd.read_csv(filename, sep=\",\").to_numpy()\n",
    "    dataset = np.where(dataset == 'I', 0, dataset)\n",
    "    dataset = np.where(dataset == 'F', 1, dataset)\n",
    "    dataset = np.where(dataset == 'M', 2, dataset)\n",
    "    \n",
    "    # splitting dataset into training set and test set\n",
    "    testData = []\n",
    "    trainingData = []\n",
    "    split_prob = 0.80\n",
    "    for i in range(dataset.shape[0]):\n",
    "        if random.random() < split_prob:\n",
    "            trainingData.append(dataset[i])\n",
    "        else:\n",
    "            testData.append(dataset[i])\n",
    "    return trainingData, testData\n",
    "\n",
    "\n",
    "# function to get euclidean distance\n",
    "def getEuclideanDistance(trainingValue, testValue):\n",
    "    distance = 0\n",
    "    for i in range(len(testValue) - 1):\n",
    "        distance += pow((trainingValue[i] - testValue[i]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "# function to get k closest neighbours of the test value\n",
    "def getClosestNeighbors(trainingData, testValue, k):\n",
    "    distances = []\n",
    "    \n",
    "    # calculating all distances between training data and test value\n",
    "    for i in range(len(trainingData)):\n",
    "        distance = getEuclideanDistance(trainingData[i], testValue)\n",
    "        distances.append((trainingData[i], distance))\n",
    "        \n",
    "    # sorting on the basis of distance\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    \n",
    "    # finding min k closest neighbours\n",
    "    closestNeighbors = []\n",
    "    for i in range(k):\n",
    "        closestNeighbors.append(distances[i][0])\n",
    "    return closestNeighbors\n",
    "\n",
    "\n",
    "# function to get predicted value i.e. the max class label value in all k closest neighbours\n",
    "def getPrediction(closestNeighbors):\n",
    "    totalClassVotes = {}\n",
    "    for i in range(len(closestNeighbors)):\n",
    "        prediction = closestNeighbors[i][-1]\n",
    "        if prediction not in totalClassVotes:\n",
    "            totalClassVotes[prediction] = 1\n",
    "        else:\n",
    "             totalClassVotes[prediction] += 1\n",
    "    totalSortedVotes = sorted(totalClassVotes.items(), key=lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "    return totalSortedVotes[0][0]\n",
    "\n",
    "\n",
    "# function to get accuracy\n",
    "def getAccuracy(testData, predictedValues):\n",
    "    correct = 0\n",
    "    for i in range(len(testData)):\n",
    "        if testData[i][-1] == predictedValues[i]:\n",
    "            correct += 1\n",
    "    accuracy = (correct/float(len(testData))) * 100.0\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "# function to get precision\n",
    "def getPrecision(testData, predictedValues, value):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for i in range(len(testData)):\n",
    "        if testData[i][-1] == predictedValues[i] and testData[i][-1] == value:\n",
    "            correct += 1\n",
    "        elif testData[i][-1] != predictedValues[i] and predictedValues[i] == value:\n",
    "            wrong += 1\n",
    "    if correct == 0 and wrong == 0:\n",
    "        return 0\n",
    "    return (correct/float(correct + wrong)) * 100.0\n",
    "    \n",
    "    \n",
    "# function to get recall\n",
    "def getRecall(testData, predictedValues, value):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for i in range(len(testData)):\n",
    "        if testData[i][-1] == predictedValues[i] and testData[i][-1] == value:\n",
    "            correct += 1\n",
    "        elif testData[i][-1] != predictedValues[i] and testData[i][-1] == value:\n",
    "            wrong += 1\n",
    "    if correct == 0 and wrong == 0:\n",
    "        return 0\n",
    "    return (correct/float(correct + wrong)) * 100.0\n",
    "    \n",
    "    \n",
    "# function to get f1-score\n",
    "def getF1Score(testData, predictedValues, value):\n",
    "    precision = getPrecision(testData, predictedValues, value)\n",
    "    recall = getRecall(testData, predictedValues, value)\n",
    "    if precision == 0 and recall == 0:\n",
    "        return 0\n",
    "    f1_score = (2*precision*recall)/(precision + recall)\n",
    "    return f1_score\n",
    "    \n",
    "    \n",
    "# function print accuracy, precision, recall and f1-score\n",
    "def printEvaluations(testData, predictedValues):\n",
    "    # printing accuracy\n",
    "    accuracy = getAccuracy(testData, predictedValues)\n",
    "    print(\"\\nFinal Accuracy: {0}%\\n\".format(accuracy))\n",
    "    \n",
    "    # finding unique class labels in test data\n",
    "    classLabels = []\n",
    "    for i in testData:\n",
    "        classLabels.append(i[len(testData[0]) - 1])\n",
    "    classLabels = np.unique(classLabels)\n",
    "    \n",
    "    # printing precision, recall, f1-score of each class label in test data\n",
    "    for classLabel in classLabels:\n",
    "        # printing class label\n",
    "        print(\"Class Label: \" + repr(classLabel))\n",
    "        \n",
    "        # printing precision\n",
    "        precision = getPrecision(testData, predictedValues, classLabel)\n",
    "        print(\"\\tPrecision: {0}%\".format(precision))\n",
    "        \n",
    "        # printing recall\n",
    "        recall = getRecall(testData, predictedValues, classLabel)\n",
    "        print(\"\\tRecall: {0}%\".format(recall))\n",
    "        \n",
    "        # printing f1-score\n",
    "        f1_score = getF1Score(testData, predictedValues, classLabel)\n",
    "        print(\"\\tF1-Score: {0}%\\n\".format(f1_score))\n",
    "    \n",
    "    \n",
    "# main function\n",
    "if __name__ == \"__main__\":\n",
    "    # reading from file and printing\n",
    "    trainingData, testData = readDataset('abalone.data')\n",
    "    print(\"Training Data: \" + repr(len(trainingData)))\n",
    "    print(\"Test Data: \" + repr(len(testData)))\n",
    "    \n",
    "    k = 5   # total number of closest neighbours\n",
    "    print(\"Value of k: \" + repr(k))\n",
    "    \n",
    "    # finding predictions of the test data\n",
    "    predictedValues=[]\n",
    "    for i in range(len(testData)):\n",
    "        closestNeighbors = getClosestNeighbors(trainingData, testData[i], k)\n",
    "        prediction = getPrediction(closestNeighbors)\n",
    "        predictedValues.append(prediction)\n",
    "    \n",
    "    # printing evaluations\n",
    "    printEvaluations(testData, predictedValues)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
